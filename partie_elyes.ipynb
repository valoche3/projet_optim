{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3a8bf4-0cb6-4fca-92fc-ab62319e0338",
   "metadata": {},
   "source": [
    "## Projet d'optimisation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecccf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from casadi import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae2cf9",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf1ee91-f74b-4534-bb59-99920b73bb17",
   "metadata": {},
   "source": [
    "Le but du problème est de trouver l'allocation globale $x \\in \\mathbb{R}^m$ qui minimise le risque associé au rendement du portefeuille, i.e. la variance de cette allocation par rapport à la variation du prix des actifs $p \\in \\mathbb{R}^m$.\n",
    "\n",
    "La variance est l'équivalent d'un \"écart à la moyenne\" ; elle représente donc bien un indicateur du risque associé à un investissement. Ce risque prend en compte le lien entre la variation des prix et les allocations, d'où $x^T \\Sigma x$, où $\\Sigma$ est la matrice de covariance associé à $p$.\n",
    "\n",
    "La relation $\\bold{1}^T x = 1$ signifie simplement que l'on normalise l'allocation par souci de cohérence et de clarté ; pour une allocation donnée, le rendement représente le gain moyen associé à l'allocation, d'où $\\bar p^T x = r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8146c-8574-4d6a-864e-4309db37404a",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4373f-3240-46fb-9905-96283f5594f0",
   "metadata": {},
   "source": [
    "On souhaite minimiser le risque, donc on a\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "f : z & \\longmapsto & f(z) = x^T \\Sigma x\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "La variable $z$ dépend donc de $x$, mais aussi de $\\Sigma = \\left[ \\mathrm{Cov}(p_i, p_j) \\right]_{i,j \\in \\llbracket 1, m \\rrbracket}$ et donc de $p$. Le nombre de variables de décisions est  $n = 2$ ($p$ et $x$), où chaque variable est un vecteur de $\\mathbb{R}^m$.\n",
    "\n",
    "L'énoncé contraint le problème par le biais des conditions de normalisation $\\bold{1}^T x = 1$ et de rendement $r = \\bar p^T x$ : on peut donc définir\n",
    "$$c_{eq}(z) = \\begin{bmatrix} \\bold{1}^T x - 1 \\\\ \\overline{p}^T x - r \\end{bmatrix} = \\underbrace{\\begin{bmatrix} \\bold{1}^T \\\\ \\overline{p}^T \\end{bmatrix}}_{\\in \\mathbb{R}^{2 \\times m}} \\cdot \\underbrace{x}_{\\in \\mathbb{R}^m} - \\underbrace{\\begin{bmatrix} 1 \\\\ r \\end{bmatrix}}_{\\in \\mathbb{R}^2}$$\n",
    "ce qui ajoute la contrainte égalité $$c_{eq}(z)  = 0$$ au problème de minimisation de $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c1e7d-7189-47a6-bff1-734f84c4c2bd",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17891231-c3c7-4dae-9a36-45602ca985fd",
   "metadata": {},
   "source": [
    "On ajoute une contrainte inégalité pour limiter les positions _short_ à un certain montant par allocation, afin de garantir un équilibre de marché, ne pas entraîner de trop fortes fluctuation des actifs et donc une variance trop élevée.\n",
    "\n",
    "On a donc dans ce problème une contrainte égalité (représentée par la fonction $c_{eq}$) et une contrainte inégalité.\n",
    "\n",
    "Or la contrainte inégalité comprend déjà une fonction $\\max$ ; on cherche donc à minimiser une fonction $f$ sous contrainte d'une limitation d'un maximum, ce qui risque de compliquer les calculs... La fonction $\\max$ est en effet non linéaire et non différentiable lorsque $x_i = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8aaf1-eeec-4950-81d1-886ed1497b7b",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c927196-71e0-4246-8123-e9faa0c72b85",
   "metadata": {},
   "source": [
    "$\\max(-x,\\bold{0})$ vérifie\n",
    "$\\forall x \\in \\mathbb{R}^m, \\max(-x,\\bold{0}) ≥ -x$ et $\\max(-x,\\bold{0}) ≥ 0$.\n",
    "\n",
    "En introduisant $s \\in \\mathbb{R}^m$ tel que $s ≥ -x$, $s ≥ 0$ et $\\bold{1}^T s ≤ s_M$, on a \n",
    "$$\\bold{1}^T \\max(-x,\\bold{0}) ≤ \\bold{1}^T s ≤ s_M$$\n",
    "En prenant $s$ le plus proche possible de $\\max(-x,\\bold{0})$, on peut reformuler de manière équivalente le problème de la question 2 :\n",
    "$$\\min f(z)$$\n",
    "sous les contraintes $$\\begin{cases} c_{eq}(z) = 0 \\\\ c_{ineq}(z) = \\begin{bmatrix} -s - x \\\\ -s \\\\ \\bold 1^{\\top}s - s_M \\end{bmatrix} ≤ 0 \\end{cases}$$ \n",
    "\n",
    "Les 3 coordonnées de $c_{ineq}$ reprennent les 3 contraintes sur s.\n",
    "\n",
    "De plus, la variable $s$ est indirectement liée à $x$, et donc à $z$, puisqu'elle est choisie en fonction de $-x$ (on veut avoir $s = \\max(-x, \\bold{0})$ en se débarrassant du max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a89a4a-e6f8-4851-b42c-1f745353ecbb",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b2778-1e94-4285-bde8-b72eae2a663e",
   "metadata": {},
   "source": [
    "Le problème $(4)$ est un problème d'optimisation sous contrainte avec des contraintes égalité linéaires (donc convexes). La fonction $f$ à minimiser est quadratique et convexe car $\\Sigma$ est semi-définie positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d32a1d",
   "metadata": {},
   "source": [
    "On peut donc penser dans un premier temps à la résolution d'un problème équivalent sans contraintes, en commençant par un algorithme d'élimination des contraintes appliqué à $c_{eq}$. Comme $f$ est 2 fois différentiable, on peut alors utiliser un algorithme utilisant une méthode de Newton, ou de quasi-Newton, comme BFGS par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39abf4",
   "metadata": {},
   "source": [
    "Une autre méthode de résolution est d'utiliser les multiplicateurs de Lagrange, en calculant le lagrangien\n",
    "$$\\mathcal{L}(z, \\lambda) = f(z) + \\lambda^T c_{eq}(z)$$\n",
    "puis en résolvant le problème dual (recherche de point de selle du lagrangien), avec un algorithme d'Uzawa ou d'Arrow-Hurwitz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07dadc",
   "metadata": {},
   "source": [
    "Dans la même veine, on peut tenter de résoudre analytiquement le problème avec les conditions $(KKT)$ : comme les contraintes sont affines, elles sont convexes, et la fonction $f$ l'est aussi donc on a une équivalence entre respecter les conditions $(KKT)$ et être solution du problème d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19d888-7ec9-459d-8c92-406cbaa6c773",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a6642",
   "metadata": {},
   "source": [
    "Pour résoudre numériquement le problème, on va utiliser les bibliothèques Scipy (avec son module _optimize_ et son solveur SLSQP) et Casadi (avec _ipopt_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b613f7-1d4e-4785-a85b-28c0e969d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des variables\n",
    "p1 = 0.05\n",
    "p2 = 0.15\n",
    "p3 = 0.3\n",
    "p = np.array([p1, p2, p3])\n",
    "rho = 0.1\n",
    "r = 0.1\n",
    "\n",
    "sig1 = 0.1\n",
    "sig2 = 0.3\n",
    "sig3 = 0.8\n",
    "sigma = np.array([[sig1**2, rho*sig1*sig2, 0], [rho*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "unit = np.ones(3)\n",
    "x0 = np.array([0., 0., 0.]) #pour remplir la condition de normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f81494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction variance et des contraintes\n",
    "\n",
    "def var(x):\n",
    "    return x.T @ sigma @ x\n",
    "\n",
    "contraintes = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76aea81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (r = 0.1)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.017067775457853502\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.63284823 0.27858628 0.08856549]\n",
      "Durée :  0.0015799999237060547\n"
     ]
    }
   ],
   "source": [
    "# BFGS avec Scipy\n",
    "print('méthode SLSQP avec Scipy (r = 0.1)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d46920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résolution avec Casadi...\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        6\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        6\n",
      "\n",
      "Total number of variables............................:        3\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        2\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  0.0000000e+00 1.00e+00 0.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  1.7067775e-02 0.00e+00 1.39e-17  -1.7 6.33e-01    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.7067775467775471e-02    1.7067775467775471e-02\n",
      "Dual infeasibility......:   1.3877787807814457e-17    1.3877787807814457e-17\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   1.3877787807814457e-17    1.3877787807814457e-17\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 2\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 2\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 0.004\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |   4.00us (  2.00us)   2.92us (  1.46us)         2\n",
      "       nlp_g  |   2.00us (  1.00us)   2.33us (  1.17us)         2\n",
      "  nlp_grad_f  |   7.00us (  2.33us)   5.37us (  1.79us)         3\n",
      "  nlp_hess_l  |   3.00us (  3.00us)   3.75us (  3.75us)         1\n",
      "   nlp_jac_g  |   5.00us (  1.67us)   5.29us (  1.76us)         3\n",
      "       total  |   2.51ms (  2.51ms)   6.04ms (  6.04ms)         1\n",
      "Durée :  0.027599096298217773\n",
      "[0.63284823 0.27858628 0.08856549]\n"
     ]
    }
   ],
   "source": [
    "# Résolution avec Casadi\n",
    "opti_cons = casadi.Opti();\n",
    "x = opti_cons.variable(3)\n",
    "\n",
    "opti_cons.minimize(var(x))\n",
    "opti_cons.subject_to(dot(unit.T, x) - 1 == 0)\n",
    "opti_cons.subject_to(dot(p.T, x) - r == 0)\n",
    "\n",
    "opti_cons.set_initial(x,x0)\n",
    "opti_cons.solver('ipopt')\n",
    "\n",
    "print(\"Résolution avec Casadi...\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2cf17",
   "metadata": {},
   "source": [
    "On remarque que le temps de calcul avec Scipy et Casadi sont sensiblement les mêmes (de l'ordre de $10^{-3}$ s)\n",
    "\n",
    "De plus, les 2 méthodes aboutissent au même résultat, à savoir une variance de l'ordre de $10^{-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f653564-ab89-4672-8140-a9efcffd3aab",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebfc741-5f25-4660-8061-b784c3fa65ea",
   "metadata": {},
   "source": [
    "$(a)$\n",
    "\n",
    "$\\rho$ est le coefficient de corrélation associé aux vecteurs $p_1$ et $p_2$ : c'est la corrélation entre les actifs. Il prend des valeurs dans l'intervalle $[-1, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d8f98-b786-4645-8383-7fd11c6d3f10",
   "metadata": {},
   "source": [
    "$(b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad56110e-0959-4842-8e30-41211616a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bba1e",
   "metadata": {},
   "source": [
    "$(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c0dbd",
   "metadata": {},
   "source": [
    "On ne résout qu'avec la méthode SLSQP de Scipy à présent pour plus de clarté, on n'utilise plus Casadi mais la réponse reste la même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951dab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (rho = 0.5)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.021123595513179938\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.65168539 0.24719102 0.10112359]\n",
      "Durée :  0.0011157989501953125\n"
     ]
    }
   ],
   "source": [
    "# rho = 0.5\n",
    "rho1 = 0.5\n",
    "sigma1 = np.array([[sig1**2, rho1*sig1*sig2, 0], [rho1*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "def var1(x):\n",
    "    return x.T @ sigma1 @ x\n",
    "\n",
    "print('méthode SLSQP avec Scipy (rho = 0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var1, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b4acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (rho = -0.5)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.010392523364486006\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.60934579 0.31775702 0.07289719]\n",
      "Durée :  0.0012850761413574219\n"
     ]
    }
   ],
   "source": [
    "# rho = -0.5\n",
    "rho2 = -0.5\n",
    "sigma2 = np.array([[sig1**2, rho2*sig1*sig2, 0], [rho2*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "def var2(x):\n",
    "    return x.T @ sigma2 @ x\n",
    "\n",
    "print('méthode SLSQP avec Scipy (rho = -0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var2, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a8643",
   "metadata": {},
   "source": [
    "SPAP analyse de la question précédente :/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f241b",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a20864",
   "metadata": {},
   "source": [
    "$(a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d16946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.2)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.10745197524851792\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [-0.0827443   0.80457383  0.27817047]\n",
      "Durée :  0.0010030269622802734\n"
     ]
    }
   ],
   "source": [
    "# Pour r = 0.2\n",
    "r1 = 0.2\n",
    "\n",
    "contraintes1 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r1})\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.2)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes1, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17ec85",
   "metadata": {},
   "source": [
    "L'optimum passe par une position courte sur l'actif 1 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b36bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.15)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.04956735987023322\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.27505197 0.54158004 0.18336798]\n",
      "Durée :  0.0010738372802734375\n"
     ]
    }
   ],
   "source": [
    "# pour r = 0.15\n",
    "r2 = 0.15\n",
    "\n",
    "contraintes2 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r2})\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.15)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes2, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8e4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# équivalent avec Casadi pour r = 0.2\\n\\nopti_cons1 = casadi.Opti();\\nx1 = opti_cons1.variable(3)\\n\\nopti_cons1.minimize(var(x1))\\nopti_cons1.subject_to(dot(unit.T, x1) - 1 == 0)\\nopti_cons1.subject_to(dot(p.T, x1) - r1 == 0)\\n\\nopti_cons1.set_initial(x1,x0)\\nopti_cons1.solver(\\'ipopt\\')\\n\\nprint(\"\\n \\n  Résolution avec Casadi\")\\nstart_time = time.time()\\nsol = opti_cons1.solve()\\nprint(\"Durée : \", time.time()-start_time)\\nprint(sol.value(x1))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# équivalent avec Casadi pour r = 0.2\n",
    "\n",
    "opti_cons1 = casadi.Opti();\n",
    "x1 = opti_cons1.variable(3)\n",
    "\n",
    "opti_cons1.minimize(var(x1))\n",
    "opti_cons1.subject_to(dot(unit.T, x1) - 1 == 0)\n",
    "opti_cons1.subject_to(dot(p.T, x1) - r1 == 0)\n",
    "\n",
    "opti_cons1.set_initial(x1,x0)\n",
    "opti_cons1.solver('ipopt')\n",
    "\n",
    "print(\"\\n \\n  Résolution avec Casadi\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons1.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63d9637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# équivalent avec Casadi pour r = 0.15\\n\\nopti_cons2 = casadi.Opti();\\nx2 = opti_cons2.variable(3)\\n\\nopti_cons2.minimize(var(x2))\\nopti_cons2.subject_to(dot(unit.T, x2) - 1 == 0)\\nopti_cons2.subject_to(dot(p.T, x2) - r2 == 0)\\n\\nopti_cons2.set_initial(x2,x0)\\nopti_cons2.solver(\\'ipopt\\')\\n\\nprint(\"\\n \\n  Résolution avec Casadi\")\\nstart_time = time.time()\\nsol = opti_cons2.solve()\\nprint(\"Durée : \", time.time()-start_time)\\nprint(sol.value(x2))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# équivalent avec Casadi pour r = 0.15\n",
    "\n",
    "opti_cons2 = casadi.Opti();\n",
    "x2 = opti_cons2.variable(3)\n",
    "\n",
    "opti_cons2.minimize(var(x2))\n",
    "opti_cons2.subject_to(dot(unit.T, x2) - 1 == 0)\n",
    "opti_cons2.subject_to(dot(p.T, x2) - r2 == 0)\n",
    "\n",
    "opti_cons2.set_initial(x2,x0)\n",
    "opti_cons2.solver('ipopt')\n",
    "\n",
    "print(\"\\n \\n  Résolution avec Casadi\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons2.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddaab95",
   "metadata": {},
   "source": [
    "Notons tout d'abord qu'un actif $i$ est d'autant plus risqué que $\\sigma_i$ est élevé. Ici on a $\\sigma_{1} = 10 \\% < \\sigma_{2} = 30 \\% < \\sigma_{3} = 80 \\%$.\n",
    "\n",
    "Le rendement d'un actif est quant à lui lié à $\\overline{p}$ : on a $\\overline{p}_1 = 5 \\% < \\overline{p}_2 = 15 \\% < \\overline{p}_3 = 30 \\%$, donc les rendements sont croissants avec le numéro de l'actif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab23761",
   "metadata": {},
   "source": [
    "Pour $r = 0,1$, qui est un rendement relativement faible, la solution optimale privilégie l'actif 1, qui est le moins risqué. Le risque du portefeuille est alors relativement faible (justifié par le faible rendement de l'investissement).\n",
    "\n",
    "Pour $r = 0,2$, plus élevé, le risque minimal augmente considérablement ; on voit apparaître une position courte sur l'actif 1, et les allocations sur les actifs 2 et 3 (plus risqués mais avec un rendement moyen plus élevé) augmentent.\n",
    "\n",
    "Pour $r = 0,15$ entre les deux, le risque et l'allocation sont intermédiaires. L'allocation est davantage répartie entre les actifs, avec notamment davantage d'investissement dans l'actif 2, et il n'y a pas de position courte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c613776",
   "metadata": {},
   "source": [
    "Ces résultats illustrent un compromis d'apparence fondamentale en finance : pour obtenir un rendement cible plus élevé, l'investisseur doit souvent accepter un niveau de risque plus élevé.\n",
    "\n",
    "De plus, on voit que le profil d'allocation change beaucoup en fonction du rendement cible ; pour obtenir des rendements cibles élevés, on s'en remet donc à utiliser des positions courtes, que l'on paye en augmentation du risque global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e02bcd",
   "metadata": {},
   "source": [
    "$(b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a9a96",
   "metadata": {},
   "source": [
    "Nous avons vu que la solution optimale pour $r = 0,15$ est intermédiaire en termes de risque et d'allocation entre les solutions pour $r = 0,1$ et $r = 0,2$. On peut donc intuiter à première vue qu'un portefeuille optimal pour un rendement entre $r = 0,1$ et $r = 0,2$ peut s'obtenir en pondérant les portefeuilles optimaux pour ces deux situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cece2",
   "metadata": {},
   "source": [
    "__Justification du _Two-Fund Theorem_ :__\n",
    "\n",
    "La frontière efficiente, telle que présentée dans l'énoncé, représente les allocations qui engendrent le plus grand retour sur investissement (à un niveau de risque donné). Les investisseurs ont donc intérêt à établir leurs allocations sur cette frontière.\n",
    "\n",
    "De plus, comme les allocations sont ici des vecteurs, connaissant les allocations de deux acteurs A et B, d'après les résultats précédents, un investisseur C peut créer son allocation en effectuant une combinaison linéaire des allocations de A et de B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9263a",
   "metadata": {},
   "source": [
    "$(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49e52b",
   "metadata": {},
   "source": [
    "Résolvons analytiquement le problème $(4)$ : pour ce faire, on va utiliser la méthode du Lagrangien, qui repose sur le fait que tout point stationnaire de $f$ est un point stationnaire du lagrangien pour un certain multiplicateur de Lagrange.\n",
    "\n",
    "On définit le lagrangien comme suit :\n",
    "$$\\mathcal{L}(z, \\lambda) =  f(z) + \\lambda^T c_{eq}(z)$$\n",
    "avec $\\lambda = \\begin{pmatrix} \\lambda_{1} \\\\ \\lambda_{2} \\end{pmatrix}$ le vecteur des multiplicateurs de Lagrange associés aux contraintes de budget et de rendement.\n",
    "\n",
    "On peut réécrire le lagrangien comme fonction de $x, \\lambda_{1}, \\lambda_{2}$ :\n",
    "$$\\mathcal{L}(x, \\lambda_{1}, \\lambda_{2}) = x^T \\Sigma x + \\lambda_{1} (\\bold{1}^T x - 1) + \\lambda_{2} (\\overline{p}^T x - r)$$\n",
    "\n",
    "La solution optimale est point stationnaire du lagrangien, d'où :\n",
    "$$\\begin{cases}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial x} = 2 \\Sigma x + \\lambda_{1} \\bold{1} + \\lambda_{2} \\overline{p} = 0 & (1)\n",
    "\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda_{1}} = \\bold{1}^T x - 1 = 0 & (2)\n",
    "\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda_{2}} = \\overline{p}^T x - r = 0 & (3)\n",
    "\\end{cases}$$\n",
    "\n",
    "De $(1)$ on déduit $x$ en fonction de $\\lambda_{1}$ et $\\lambda_{2}$ :\n",
    "$$ x = -2 \\Sigma^{-1} [\\lambda_{1} \\bold{1} + \\lambda_{2} \\overline{p}]$$\n",
    "\n",
    "On réinjecte dans $(2)$ et $(3)$ :\n",
    "$$\\begin{cases}\n",
    "\\frac{1}{2} \\big ( \\lambda_{1} \\bold{1}^T \\Sigma^{-1} \\bold{1} + \\lambda_{2} \\bold{1}^T \\Sigma^{-1} \\overline{p} \\big ) = -1\n",
    "\\\\\n",
    "\\frac{1}{2} \\big ( \\lambda_{1} \\overline{p}^T \\Sigma^{-1} \\bold{1} + \\lambda_{2} \\overline{p}^T \\Sigma^{-1} \\overline{p} \\big ) = -r\n",
    "\\end{cases}$$\n",
    "\n",
    "Pour simplifier les notations, on pose :\n",
    "$$A = \\bold{1}^T \\Sigma^{-1} \\bold{1} \\; ; \\; B = \\bold{1}^T \\Sigma^{-1} \\overline{p} = \\overline{p}^T \\Sigma^{-1} \\bold{1} \\; ; \\; C = \\overline{p}^T \\Sigma^{-1} \\overline{p}$$\n",
    "\n",
    "Notons que $A$, $B$ et $C$ ne dépendent pas de $r$ mais seulement des paramètres de marché.\n",
    "\n",
    "On a alors un système de deux équations à deux inconnues ($\\lambda_{1}$ et $\\lambda_{2}$), qu'on résout :\n",
    "$$\\begin{cases}\n",
    "\\lambda_{1} A + \\lambda_{2} B = -2\n",
    "\\\\\n",
    "\\lambda_{1} B + \\lambda_{2} C = -2r\n",
    "\\end{cases}\n",
    "\\iff\n",
    "\\begin{cases}\n",
    "\\lambda_{1} = -2 \\frac{rB - C}{B^2 - AC}\n",
    "\\\\\n",
    "\\lambda_{2} = 2 \\frac{rA - B}{B^2 - AC}\n",
    "\\end{cases}$$\n",
    "\n",
    "qui existent _ssi_ $B^2 ≠ AC$, condition que l'on va considérer comme remplie.\n",
    "\n",
    "En réinjectant, on obtient alors une expression explicite de $x^*$, qu'on peut regrouper de la sorte :\n",
    "$$x^* = A' + B' r$$\n",
    "avec $A'$, $B'$ dépendant des paramètres de marché mais pas de $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76713e11",
   "metadata": {},
   "source": [
    "Ainsi, tout portefeuille efficient $x^*(r)$ peut être exprimé comme combinaison linéaire de deux portefeuilles, représentés par les vecteurs $A$ et $B$ et ne dépendant pas de $r$ ; on obtient donc un ensemble de portefeuilles efficients avec 2 portefeuilles de base, ce qui achève la preuve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0dfc0",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ebff019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.4, s_M = 0.5)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.1422777808842124\n",
      "            Iterations: 3\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 3\n",
      "Allocation : [-0.5         0.16666666  1.33333334]\n",
      "Durée :  0.0019519329071044922\n"
     ]
    }
   ],
   "source": [
    "r9 = 0.4\n",
    "s_M = 0.5\n",
    "x0 = np.array([0., 0., 0.])\n",
    "\n",
    "# Comme x et s sont liées, on va créer un array 'variables' de taille 6 qui contient la concaténation de x et de s\n",
    "def var2(variables):\n",
    "    x = variables[:3]\n",
    "    return x.T @ sigma @ x\n",
    "\n",
    "# ATTENTION : les contraintes inégalités sont traitées dans \"l'autre sens\" par scipy.optimize.minimize\n",
    "def contrainte_sx(variables):\n",
    "    x = variables[:3]\n",
    "    s = variables[3:]\n",
    "    return s + x #on veut la contrainte inégalité s >= -x\n",
    "\n",
    "def contrainte_spos(variables):\n",
    "    s = variables[3:]\n",
    "    return s\n",
    "\n",
    "def contrainte_sM(variables):\n",
    "    s = variables[3:]\n",
    "    return s_M - unit.T@s\n",
    "\n",
    "contraintes9 = ({'type': 'eq', 'fun': lambda variables:  unit.T@variables[:3] -1},\n",
    "        {'type': 'eq', 'fun': lambda variables: p.T@variables[:3] - r9},\n",
    "        {'type': 'ineq', 'fun': contrainte_sx},\n",
    "        {'type': 'ineq', 'fun': contrainte_spos},\n",
    "        {'type': 'ineq', 'fun': contrainte_sM})\n",
    "\n",
    "variables0 = np.concatenate((x0, np.zeros(3)), axis=0) #initialisation de x et s\n",
    "bounds_x = [(None, None)] * 3 #pas d'encadrement de x\n",
    "bounds_s = [(0, None)]*3 #pour s'assurer que s >= 0\n",
    "bounds = bounds_x + bounds_s\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.4, s_M = 0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var2, variables0, method='SLSQP', jac=None, bounds=bounds, constraints=contraintes9, options={'disp': True})\n",
    "print(\"Allocation :\", res.x[:3]) #on n'affiche que x, pas s\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf879192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.4)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.5928407419086085\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [-1.51392947  1.85654913  0.65738034]\n",
      "Durée :  0.0011141300201416016\n"
     ]
    }
   ],
   "source": [
    "# Comparaison avec l'algorithme précédent sans les contraintes inégalité\n",
    "r3 = 0.4\n",
    "\n",
    "contraintes3 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r3})\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.4)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes3, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de453f",
   "metadata": {},
   "source": [
    "Le risque minimal est beaucoup plus élevé que celui sans limitation des positions courtes. Les positions courtes offrent en effet une flexibilité pour les investisseurs de parier _contre_ certains actifs, ce qui peut réduire le risque global dans certaines situations. Par essence, ajouter une contrainte réduit l'ensemble de recherche des solutions, et donc peut potentiellement ne plus inclure le minimum global de la fonction.\n",
    "\n",
    "En revanche, les investissements sont moins extrêmes : en effet, en limitant les positions courtes, on limite aussi la diversification des allocations et l'écart d'investissement entre les actifs (on ne peut pas compenser les pertes potentielles sur une allocation avec des positions short pour un autre actif).\n",
    "\n",
    "On remarque enfin que la contrainte sur la position courte est **active** dans la résolution de cette question, puisque la position courte sur l'actif 1 est réduite à $-0,5$, ce qui est la limite imposée par $s_M$. Ainsi la contrainte a bien eu un effet direct sur la solution.\n",
    "\n",
    "En conclusion, la limitation des positions courtes augmente le risque minimal du portefeuille puisqu'il restreint l'espace des solutions ; cette restriction modifie donc l'allocation optimale des actifs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9def3",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671edd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition de la nouvelle fonction coût\n",
    "mu = 1 #juste pour initialiser mu > 0\n",
    "\n",
    "def cost(x):\n",
    "    return -p.T @ x + mu*x.T @ sigma @ x\n",
    "\n",
    "contrainte11 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b70ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (mu = 0)\n",
      "Rank-deficient equality constraint subproblem HFTI    (Exit mode 7)\n",
      "            Current function value: -62791459097741.95\n",
      "            Iterations: 38\n",
      "            Function evaluations: 162\n",
      "            Gradient evaluations: 38\n",
      "Allocation : [-2.51162433e+14 -5.67420297e+09  2.51168106e+14]\n",
      "Durée :  0.010818958282470703\n"
     ]
    }
   ],
   "source": [
    "mu = 0\n",
    "\n",
    "print('méthode SLSQP avec Scipy (mu = 0)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(cost, x0, method='SLSQP', jac=None, constraints=contrainte11, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c7b8d",
   "metadata": {},
   "source": [
    "L'algorithme a du mal à résoudre le problème car la contrainte de budget seule rend le système redondant (d'où le problème de rang). On pourrait améliorer la situation en renseignant une tolérance avec l'argument $\\texttt{tol}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "138b53bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (mu = 0)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 934038754.4229734\n",
      "            Iterations: 5\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 5\n",
      "Allocation : [0.91202439 0.07338127 0.01459435]\n",
      "Durée :  0.004523754119873047\n"
     ]
    }
   ],
   "source": [
    "mu = 10e10 #mu tend vers l'infini\n",
    "\n",
    "print('méthode SLSQP avec Scipy (mu = 0)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(cost, x0, method='SLSQP', jac=None, constraints=contrainte11, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68aa91",
   "metadata": {},
   "source": [
    "Les résultats de la simulation confirment notre prédiction de comportement. Le cas $\\mu \\to +\\infty$ signifie qu'on accorde une importance _infiniment plus grande_ à la minimisation du risque qu'à la maximisation du rendement. L'investisseur cherchera donc l'allocation qui a la variance la plus faible, en accordant une importance négligeable au rendement de cette allocation. Il privilégie donc les actifs les moins risqués, même s'ils impliquent un plus faible rendement : on obtient donc un placement majoritaire sur $x_1$, comme le montre la simulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
