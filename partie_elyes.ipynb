{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3a8bf4-0cb6-4fca-92fc-ab62319e0338",
   "metadata": {},
   "source": [
    "## Projet d'optimisation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecccf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from casadi import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae2cf9",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf1ee91-f74b-4534-bb59-99920b73bb17",
   "metadata": {},
   "source": [
    "Le but du problème est de trouver l'allocation globale $x \\in \\mathbb{R}^m$ qui minimise le risque associé au rendement du portefeuille, i.e. la variance de cette allocation par rapport à la variation du prix des actifs $p \\in \\mathbb{R}^m$.\n",
    "\n",
    "La variance est l'équivalent d'un \"écart à la moyenne\" ; elle représente donc bien un indicateur du risque associé à un investissement. Ce risque prend en compte le lien entre la variation des prix et les allocations, d'où $x^T \\Sigma x$, où $\\Sigma$ est la matrice de covariance associé à $p$.\n",
    "\n",
    "La relation $\\bold{1}^T x = 1$ signifie simplement que l'on normalise l'allocation par souci de cohérence et de clarté ; pour une allocation donnée, le rendement représente le gain moyen associé à l'allocation, d'où $\\bar p^T x = r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8146c-8574-4d6a-864e-4309db37404a",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c4373f-3240-46fb-9905-96283f5594f0",
   "metadata": {},
   "source": [
    "On souhaite minimiser le risque, donc on a\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "f : z & \\longmapsto & f(z) = x^T \\Sigma x\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "La variable $z$ dépend donc de $x$, mais aussi de $\\Sigma = \\left[ \\mathrm{Cov}(p_i, p_j) \\right]_{i,j \\in \\llbracket 1, m \\rrbracket}$ et donc de $p$. Le nombre de variables de décisions est donc $n = 2$, où chaque variable est un vecteur de $\\mathbb{R}^m$.\n",
    "\n",
    "L'énoncé contraint le problème par le biais de la condition de normalisation $\\bold{1}^T x = 1$ et celle de rendement $r = \\bar p^T x$ : on peut donc définir $$c_{eq,norm}(z) = \\bold{1}^T x - 1$$ et $$c_{eq,rend}(z) = \\bar p^T x - r$$ ce qui ajoute les contraintes égalité $c_{eq} : \\begin{cases} c_{eq,norm}(z) = 0 \\\\ c_{eq,rend}(z) = 0 \\end{cases}$ au problème de minimisation de $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c1e7d-7189-47a6-bff1-734f84c4c2bd",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17891231-c3c7-4dae-9a36-45602ca985fd",
   "metadata": {},
   "source": [
    "On ajoute une contrainte inégalité pour limiter les positions _short_ à un certain montant par allocation, afin de garantir un équilibre de marché, ne pas entraîner de trop fortes fluctuation des actifs et donc une variance trop élevée.\n",
    "\n",
    "On a donc dans ce problème une contrainte égalité (représentée par la fonction $c_{eq}$) et une contrainte inégalité.\n",
    "\n",
    "Or la contrainte inégalité comprend déjà une fonction $max$ ; on cherche donc à minimiser une fonction $f$ sous contrainte d'une limitation d'un maximum, ce qui risque de compliquer les calculs..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8aaf1-eeec-4950-81d1-886ed1497b7b",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c927196-71e0-4246-8123-e9faa0c72b85",
   "metadata": {},
   "source": [
    "$\\max(-x,\\bold{0})$ vérifie\n",
    "$\\forall x \\in \\mathbb{R}^m, \\max(-x,\\bold{0}) ≥ -x$ et $\\max(-x,\\bold{0}) ≥ 0$.\n",
    "\n",
    "En introduisant $s \\in \\mathbb{R}^m$ tel que $s ≥ -x$, $s ≥ 0$ et $\\bold{1}^T s ≤ s_M$, on a \n",
    "$$\\bold{1}^T \\max(-x,\\bold{0}) ≤ \\bold{1}^T s ≤ s_M$$\n",
    "En prenant $s$ le plus proche possible de $\\max(-x,\\bold{0})$, on peut reformuler de manière équivalente le problème de la question 2 :\n",
    "$$\\min f(z)$$\n",
    "sous les contraintes $c_{eq}(z) = 0$, $c_{in}(s) ≤ 0$ \n",
    "\n",
    "avec $\\begin{cases} s ≥ -x \\\\ s ≥ 0 \\end{cases}$ et $c_{in}(s) = \\bold{1}^T s - s_M$\n",
    "\n",
    "La variable $s$ est indirectement liée à $x$, et donc à $z$, puisqu'elle est choisie en fonction de $-x$ (on veut avoir $s = \\max(-x, \\bold{0})$ en se débarrassant du max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a89a4a-e6f8-4851-b42c-1f745353ecbb",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b2778-1e94-4285-bde8-b72eae2a663e",
   "metadata": {},
   "source": [
    "Le problème $(4)$ est un problème d'optimisation sous contrainte avec une contrainte égalité affine.\n",
    "\n",
    "Une première méthode de résolution est d'utiliser les multiplicateurs de Lagrange, en calculant le lagrangien\n",
    "$$\\mathcal{L}(z, \\lambda) = f(z) + \\lambda^T c_{eq}(z)$$\n",
    "puis en  trouvant ses points stationnaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07dadc",
   "metadata": {},
   "source": [
    "On peut aussi penser aux conditions $(KKT)$ : en effet, une contrainte affine étant convexe, on a une équivalence entre respecter les conditions $(KKT)$ et être solution du problème d'optimisation sous contrainte affine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19d888-7ec9-459d-8c92-406cbaa6c773",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a6642",
   "metadata": {},
   "source": [
    "Pour résoudre numériquement le problème, on va utiliser les bibliothèques Scipy (avec son module _optimize_ et son solveur SLSQP) et Casadi (avec _ipopt_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94b613f7-1d4e-4785-a85b-28c0e969d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des variables\n",
    "p1 = 0.05\n",
    "p2 = 0.15\n",
    "p3 = 0.3\n",
    "p = np.array([p1, p2, p3])\n",
    "rho = 0.1\n",
    "r = 0.1\n",
    "\n",
    "sig1 = 0.1\n",
    "sig2 = 0.3\n",
    "sig3 = 0.8\n",
    "sigma = np.array([[sig1**2, rho*sig1*sig2, 0], [rho*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "unit = np.ones(3)\n",
    "x0 = np.array([0.3, 0.2, 0.5]) #pour remplir la condition de normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4f81494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction f et des contraintes\n",
    "\n",
    "def var(x):\n",
    "    return x.T @ sigma @ x\n",
    "\n",
    "contraintes = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76aea81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (r = 0.1)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.01706777546777549\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.63284823 0.27858629 0.08856549]\n",
      "Durée :  0.007384777069091797\n"
     ]
    }
   ],
   "source": [
    "# BFGS avec Scipy\n",
    "print('méthode SLSQP avec Scipy (r = 0.1)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d46920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résolution avec Casadi...\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        6\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        6\n",
      "\n",
      "Total number of variables............................:        3\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        2\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.6486000e-01 9.50e-02 1.46e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  1.7067775e-02 0.00e+00 1.11e-16  -2.5 4.11e-01    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.7067775467775468e-02    1.7067775467775468e-02\n",
      "Dual infeasibility......:   1.1102230246251565e-16    1.1102230246251565e-16\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   1.1102230246251565e-16    1.1102230246251565e-16\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 2\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 2\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 0.008\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |   3.00us (  1.50us)   3.25us (  1.62us)         2\n",
      "       nlp_g  |   5.00us (  2.50us)   4.21us (  2.10us)         2\n",
      "  nlp_grad_f  |  10.00us (  3.33us)   8.67us (  2.89us)         3\n",
      "  nlp_hess_l  |   5.00us (  5.00us)   4.17us (  4.17us)         1\n",
      "   nlp_jac_g  |  12.00us (  4.00us)   9.42us (  3.14us)         3\n",
      "       total  |   5.54ms (  5.54ms)  11.54ms ( 11.54ms)         1\n",
      "Durée :  0.02812790870666504\n",
      "[0.63284823 0.27858628 0.08856549]\n"
     ]
    }
   ],
   "source": [
    "# Résolution avec Casadi\n",
    "opti_cons = casadi.Opti();\n",
    "x = opti_cons.variable(3)\n",
    "\n",
    "opti_cons.minimize(var(x))\n",
    "opti_cons.subject_to(dot(unit.T, x) - 1 == 0)\n",
    "opti_cons.subject_to(dot(p.T, x) - r == 0)\n",
    "\n",
    "opti_cons.set_initial(x,x0)\n",
    "opti_cons.solver('ipopt')\n",
    "\n",
    "print(\"Résolution avec Casadi...\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2cf17",
   "metadata": {},
   "source": [
    "On remarque que le temps de calcul avec Scipy et Casadi sont sensiblement les mêmes (de l'ordre de $10^{-3}$ s)\n",
    "\n",
    "De plus, les 2 méthodes aboutissent au même résultat, à savoir une variance de l'ordre de $10^{-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f653564-ab89-4672-8140-a9efcffd3aab",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebfc741-5f25-4660-8061-b784c3fa65ea",
   "metadata": {},
   "source": [
    "$(a)$\n",
    "\n",
    "$\\rho$ est le coefficient de corrélation associé aux vecteurs $p_1$ et $p_2$. Il peut prendre des valeurs dans l'intervalle $[-1, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d8f98-b786-4645-8383-7fd11c6d3f10",
   "metadata": {},
   "source": [
    "$(b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad56110e-0959-4842-8e30-41211616a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bba1e",
   "metadata": {},
   "source": [
    "$(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c0dbd",
   "metadata": {},
   "source": [
    "On ne résout qu'avec la méthode SLSQP de Scipy à présent pour plus de clarté, on n'utilise plus Casadi mais la réponse reste la même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "951dab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (rho = 0.5)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.021123595533492193\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.65168539 0.24719102 0.10112359]\n",
      "Durée :  0.0017781257629394531\n"
     ]
    }
   ],
   "source": [
    "# rho = 0.5\n",
    "rho1 = 0.5\n",
    "sigma1 = np.array([[sig1**2, rho1*sig1*sig2, 0], [rho1*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "def var1(x):\n",
    "    return x.T @ sigma1 @ x\n",
    "\n",
    "print('méthode SLSQP avec Scipy (rho = 0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var1, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20b4acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode SLSQP avec Scipy (rho = -0.5)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.01039252337681496\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.60934579 0.31775702 0.07289719]\n",
      "Durée :  0.0018308162689208984\n"
     ]
    }
   ],
   "source": [
    "# rho = -0.5\n",
    "rho2 = -0.5\n",
    "sigma2 = np.array([[sig1**2, rho2*sig1*sig2, 0], [rho2*sig1*sig2, sig2**2, 0], [0, 0, sig3**2]])\n",
    "\n",
    "def var2(x):\n",
    "    return x.T @ sigma2 @ x\n",
    "\n",
    "print('méthode SLSQP avec Scipy (rho = -0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var2, x0, method='SLSQP', jac=None, constraints=contraintes, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a8643",
   "metadata": {},
   "source": [
    "SPAP analyse de la question précédente :/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f241b",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a20864",
   "metadata": {},
   "source": [
    "$(a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0d16946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.2)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.10745197508500445\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [-0.08274429  0.80457381  0.27817048]\n",
      "Durée :  0.0018529891967773438\n"
     ]
    }
   ],
   "source": [
    "# Pour r = 0.2\n",
    "r1 = 0.2\n",
    "\n",
    "contraintes1 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r1})\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.2)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes1, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17ec85",
   "metadata": {},
   "source": [
    "L'optimum passe ici par une allocation négative dans le _set_ total !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b36bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.15)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.04956735970798472\n",
      "            Iterations: 4\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 4\n",
      "Allocation : [0.27505198 0.54158003 0.18336799]\n",
      "Durée :  0.005079030990600586\n"
     ]
    }
   ],
   "source": [
    "# pour r = 0.15\n",
    "r2 = 0.15\n",
    "\n",
    "contraintes2 = ({'type': 'eq', 'fun': lambda x:  unit.T@x -1},\n",
    "        {'type': 'eq', 'fun': lambda x: p.T@x - r2})\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.15)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var, x0, method='SLSQP', jac=None, constraints=contraintes2, options={'disp': True})\n",
    "print(\"Allocation :\", res.x)\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c8e4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# équivalent avec Casadi pour r = 0.2\\n\\nopti_cons1 = casadi.Opti();\\nx1 = opti_cons1.variable(3)\\n\\nopti_cons1.minimize(var(x1))\\nopti_cons1.subject_to(dot(unit.T, x1) - 1 == 0)\\nopti_cons1.subject_to(dot(p.T, x1) - r1 == 0)\\n\\nopti_cons1.set_initial(x1,x0)\\nopti_cons1.solver(\\'ipopt\\')\\n\\nprint(\"\\n \\n  Résolution avec Casadi\")\\nstart_time = time.time()\\nsol = opti_cons1.solve()\\nprint(\"Durée : \", time.time()-start_time)\\nprint(sol.value(x1))\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# équivalent avec Casadi pour r = 0.2\n",
    "\n",
    "opti_cons1 = casadi.Opti();\n",
    "x1 = opti_cons1.variable(3)\n",
    "\n",
    "opti_cons1.minimize(var(x1))\n",
    "opti_cons1.subject_to(dot(unit.T, x1) - 1 == 0)\n",
    "opti_cons1.subject_to(dot(p.T, x1) - r1 == 0)\n",
    "\n",
    "opti_cons1.set_initial(x1,x0)\n",
    "opti_cons1.solver('ipopt')\n",
    "\n",
    "print(\"\\n \\n  Résolution avec Casadi\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons1.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63d9637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# équivalent avec Casadi pour r = 0.15\\n\\nopti_cons2 = casadi.Opti();\\nx2 = opti_cons2.variable(3)\\n\\nopti_cons2.minimize(var(x2))\\nopti_cons2.subject_to(dot(unit.T, x2) - 1 == 0)\\nopti_cons2.subject_to(dot(p.T, x2) - r2 == 0)\\n\\nopti_cons2.set_initial(x2,x0)\\nopti_cons2.solver(\\'ipopt\\')\\n\\nprint(\"\\n \\n  Résolution avec Casadi\")\\nstart_time = time.time()\\nsol = opti_cons2.solve()\\nprint(\"Durée : \", time.time()-start_time)\\nprint(sol.value(x2))\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# équivalent avec Casadi pour r = 0.15\n",
    "\n",
    "opti_cons2 = casadi.Opti();\n",
    "x2 = opti_cons2.variable(3)\n",
    "\n",
    "opti_cons2.minimize(var(x2))\n",
    "opti_cons2.subject_to(dot(unit.T, x2) - 1 == 0)\n",
    "opti_cons2.subject_to(dot(p.T, x2) - r2 == 0)\n",
    "\n",
    "opti_cons2.set_initial(x2,x0)\n",
    "opti_cons2.solver('ipopt')\n",
    "\n",
    "print(\"\\n \\n  Résolution avec Casadi\")\n",
    "start_time = time.time()\n",
    "sol = opti_cons2.solve()\n",
    "print(\"Durée : \", time.time()-start_time)\n",
    "print(sol.value(x2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c613776",
   "metadata": {},
   "source": [
    "On voit que la variance est une fonction croissante du rendement $r$ (on passe de $10^{-2}$ à $10^{-1}$ sur une variation assez faible de rendement, de l'ordre de quelques centièmes).\n",
    "\n",
    "On retrouve l'idée intuitive que pour un rendement d'investissement élevé (à prix équivalents), les allocations se concentrent davantage sur les actifs qui engendrent du bénéfice, mais donc le risque augmente aussi car on obtient des allocations réparties moins \"uniformément\" entre les différents actifs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e02bcd",
   "metadata": {},
   "source": [
    "$(b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cece2",
   "metadata": {},
   "source": [
    "__Justification du _Two-Fund Theorem_ :__\n",
    "\n",
    "La frontière efficace, telle que présentée dans l'énoncé, représente les allocations qui engendrent le plus grand retour sur investissement (à un niveau de risque donné). Les investisseurs ont donc intérêt à établir leurs allocations sur cette frontière.\n",
    "\n",
    "De plus, comme les allocations sont ici des vecteurs, connaissant les allocations de deux acteurs A et B, un investisseur C peut créer son allocation en effectuant une combinaison linéaire des allocations de A et de B.\n",
    "\n",
    "L'énoncé du théorème vient de la nature de la courbe de frontière efficace : c'est une hyperbole, donc on peut reconstruire un investissement à partir de 2 investissements sur cette hyperbole. Ainsi, un investisseur qui a accès à 2 fonds \"optimaux\" peut choisir son allocation (en fonction de son aversion au risque) en se ajustant les proportions d'investissement sur ces deux fonds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9263a",
   "metadata": {},
   "source": [
    "$(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c12ee8",
   "metadata": {},
   "source": [
    "*Gemini*\n",
    "\n",
    "You're asking for the analytical proof of the Two-Fund Theorem, which is the heart of Question 8c. This is a more involved derivation. Here's how we can approach it:\n",
    "\n",
    "**1. Problem Formulation**\n",
    "\n",
    "We start with the Markowitz portfolio optimization problem (4) from your document:\n",
    "\n",
    "```\n",
    "min  x'Σx\n",
    "```\n",
    "\n",
    "Subject to:\n",
    "\n",
    "```\n",
    "1'x = 1   (1)\n",
    "p'x = r   (2)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* `x` is the vector of portfolio weights.\n",
    "* `Σ` is the covariance matrix.\n",
    "* `p` is the vector of expected returns.\n",
    "* `r` is the target expected return.\n",
    "* `1` is a vector of ones.\n",
    "\n",
    "**2. Lagrangian**\n",
    "\n",
    "To solve this constrained optimization problem analytically, we use the method of Lagrange multipliers. We define the Lagrangian function:\n",
    "\n",
    "```\n",
    "L(x, λ, μ) = x'Σx + λ(1'x - 1) + μ(p'x - r)\n",
    "```\n",
    "\n",
    "Where λ and μ are Lagrange multipliers associated with the constraints (1) and (2), respectively.\n",
    "\n",
    "**3. First-Order Conditions**\n",
    "\n",
    "To find the optimal solution, we take the derivative of the Lagrangian with respect to x, λ, and μ and set them equal to zero:\n",
    "\n",
    "* ∂L/∂x = 2Σx + λ1 + μp = 0   (3)\n",
    "* ∂L/∂λ = 1'x - 1 = 0   (4)\n",
    "* ∂L/∂μ = p'x - r = 0   (5)\n",
    "\n",
    "**4. Solving for x**\n",
    "\n",
    "From equation (3), we can solve for x:\n",
    "\n",
    "```\n",
    "x = -1/2 Σ⁻¹(λ1 + μp)   (6)\n",
    "```\n",
    "\n",
    "**5. Substituting into Constraints**\n",
    "\n",
    "Now, substitute this expression for x into the constraint equations (4) and (5):\n",
    "\n",
    "* 1'(-1/2 Σ⁻¹(λ1 + μp)) = 1   (7)\n",
    "* p'(-1/2 Σ⁻¹(λ1 + μp)) = r   (8)\n",
    "\n",
    "**6. Matrix Notation**\n",
    "\n",
    "Let's define some helpful notation:\n",
    "\n",
    "* A = 1'Σ⁻¹1\n",
    "* B = 1'Σ⁻¹p = p'Σ⁻¹1\n",
    "* C = p'Σ⁻¹p\n",
    "\n",
    "Using this, we can rewrite equations (7) and (8) as:\n",
    "\n",
    "* -1/2 (λA + μB) = 1   (9)\n",
    "* -1/2 (λB + μC) = r   (10)\n",
    "\n",
    "**7. Solving for Lagrange Multipliers**\n",
    "\n",
    "Now we have a system of two linear equations (9) and (10) with two unknowns (λ and μ). We can solve for λ and μ:\n",
    "\n",
    "```\n",
    "λ = -2(C - rB) / (AC - B²)\n",
    "μ = 2(rA - B) / (AC - B²)\n",
    "```\n",
    "\n",
    "**8. Substituting Back into x**\n",
    "\n",
    "Substitute these expressions for λ and μ back into equation (6) to get the optimal portfolio weights x:\n",
    "\n",
    "```\n",
    "x = Σ⁻¹ [ (C - rB) / (AC - B²) ] 1 + Σ⁻¹ [ (rA - B) / (AC - B²) ] p\n",
    "```\n",
    "\n",
    "**9. Two-Fund Theorem**\n",
    "\n",
    "Notice that this equation can be rewritten as a linear combination of two portfolios:\n",
    "\n",
    "```\n",
    "x = α * Σ⁻¹1 + β * Σ⁻¹p\n",
    "```\n",
    "\n",
    "Where α and β are scalar coefficients that depend on A, B, C, and the target return r.\n",
    "\n",
    "This shows that any optimal portfolio x can be expressed as a combination of two specific portfolios: Σ⁻¹1 and Σ⁻¹p. These two portfolios are the \"two funds.\" By varying α and β, we can generate any portfolio on the efficient frontier.\n",
    "\n",
    "**In Conclusion**\n",
    "\n",
    "The analytical solution demonstrates that the optimal portfolio weights are always a linear combination of two specific portfolios, thus proving the Two-Fund Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0dfc0",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ebff019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Méthode SLSQP avec Scipy (r = 0.4, s_M = 0.5)\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.16486000759578212\n",
      "            Iterations: 17\n",
      "            Function evaluations: 230\n",
      "            Gradient evaluations: 17\n",
      "Allocation : [0.3        0.19999999 0.50000001]\n",
      "Durée :  0.019878864288330078\n"
     ]
    }
   ],
   "source": [
    "r9 = 0.4\n",
    "s_M = 0.5\n",
    "\n",
    "# Comme x et s sont liées, on va créer un array 'variables' de taille 6 qui contient la concaténation de x et de s\n",
    "def var2(variables):\n",
    "    x = variables[:3]\n",
    "    return x.T @ sigma @ x\n",
    "\n",
    "def contrainte_sx(variables):\n",
    "    x = variables[:3]\n",
    "    s = variables[3:]\n",
    "    return -(s + x) #on veut la contrainte inégalité s >= -x\n",
    "\n",
    "def contrainte_spos(variables):\n",
    "    s = variables[3:]\n",
    "    return -s\n",
    "\n",
    "def contrainte_sM(variables):\n",
    "    s = variables[3:]\n",
    "    return unit.T@s - s_M\n",
    "\n",
    "contraintes9 = ({'type': 'eq', 'fun': lambda variables:  unit.T@variables[:3] -1},\n",
    "        {'type': 'eq', 'fun': lambda variables: p.T@variables[:3] - r9},\n",
    "        {'type': 'ineq', 'fun': contrainte_sx},\n",
    "        {'type': 'ineq', 'fun': contrainte_spos},\n",
    "        {'type': 'ineq', 'fun': contrainte_sM})\n",
    "\n",
    "variables0 = np.concatenate((x0, np.zeros(3)), axis=0) #initialisation de x et s\n",
    "bounds_x = [(None, None)] * 3 #pas d'encadrement de x\n",
    "bounds_s = [(0, None)]*3 #pour s'assurer que s >= 0\n",
    "bounds = bounds_s + bounds_x\n",
    "\n",
    "print('  Méthode SLSQP avec Scipy (r = 0.4, s_M = 0.5)')\n",
    "start_time = time.time()\n",
    "res = optimize.minimize(var2, variables0, method='SLSQP', jac=None, bounds=bounds, constraints=contraintes9, options={'disp': True})\n",
    "print(\"Allocation :\", res.x[:3]) #on n'affiche que x, pas s\n",
    "print(\"Durée : \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de453f",
   "metadata": {},
   "source": [
    "On obtient une variance plus élevée (ce qui est prévisible étant donné que $r$ est plus élevé), mais tout de même moins élevée que celle avec $r = 0,4$ dans la configuration où on ne définit pas la contrainte inégalité : limiter les _shortings_ permet de limiter les fluctuations du marché, et donc d'avoir des variations de prix des actifs moins élevées. Le risque associé diminue donc.\n",
    "\n",
    "En revanche, les actifs sont davantage distribués : en effet, en limitant les positions courtes, on limite aussi la diversification des allocations et l'écart d'investissement entre les actifs (on ne peut pas compenser les pertes potentielles sur une allocation avec des positions short pour un autre actif)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
